{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "38740d3277777e2cd7c6c2cc9d8addf5118fdf3f82b1b39231fd12aeac8aee8b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Scikit-learn——LogisticRegression与SGDClassifier\n",
    "\n",
    "## 1 sklearn.linear_model.logistic regression\n",
    "\n",
    "* 一般来说，逻辑回归用梯度下降算法来求解参数比较常见；所以这也导致一开始误以为LogisticRegression模型就是用梯度下降算法来实现的，当遇到SGDClassifier（Stochastic Gradient Descent）随机梯度下降分类器的时候，就有点蒙了。梯度下降明明是一个求解算法，怎么就和分类器扯上关系了。原来SGDClassifier是一系列采用了梯度下降来求解参数的算法的集合，例如（SVM, logistic regression)等；\n",
    "\n",
    "* 而sklearn中，LogisticRegression的实现方法是基于“liblinear”, “newton-cg”, “lbfgs” and “sag”这些库来实现的，当数据集特别大的时候，推荐使用SGDClassifier中的逻辑回归。下面简单介绍一下LogisticRegression的使用。\n",
    "\n",
    "```\n",
    "lr=LogisticRegression() # 初始化模型\n",
    "lr.fit(X_train,y_train) # 拟合\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2 sklearn.linear_model.SGDClassifier\n",
    "\n",
    "* SGDClassifier是一个用随机梯度下降算法训练的线性分类器的集合。默认情况下是一个线性（软间隔）支持向量机分类器。顺便说一句，有人可能会疑惑：大多数SVM的求解不都是用的SMO算法么？怎么这儿又跑来一个SGD算法。原因是因为,支持向量机的另一个解释就是最小化合页损失函数（详见李航统计学习方法P113）。因此，该损失函数同样可以通过梯度下降算法来求解参数。下面是SGDClassifier的基本使用方法：\n",
    "\n",
    "* 需要注意的是，梯度下降对数据的范围异常敏感，所有要先进行Feature scaling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-5-9c4803239723>, line 44)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-9c4803239723>\"\u001b[1;36m, line \u001b[1;32m44\u001b[0m\n\u001b[1;33m    print((classification_report(y_test,sgdc_pre,target_names=['Benign','Malignant']))\u001b[0m\n\u001b[1;37m                                                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "column_name=['Sample code number','Clump Thickness','Uniformity of Cell Size',\n",
    "'Uniformity of Cell Shape','Marginal Adhesion','Single Epithelial Cell Size',\n",
    "'Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses','Class']\n",
    "\n",
    "data=pd.read_csv('./DataSets/breast-cancer-wisconsin.data',names=column_name) \n",
    "# 读取数据集\n",
    "\n",
    "data=data.replace(to_replace='?',value=np.nan) \n",
    "#将缺失值替换成NAN,(原始数据集缺失值用的是问号)\n",
    "\n",
    "data=data.dropna(how='any') \n",
    "# 去掉所有包含缺失值的样本点\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(data[column_name[1:10]],data[column_name[10]],test_size=0.25,random_state=33) \n",
    "# 取前10列为X，第10列为y，并且分割；random_state参数的作用是为了保证每次运行程序时都以同样的方式进行分割\n",
    "\n",
    "#print y_train.value_counts() # 查看分割后的数据集\n",
    "#print y_test.value_counts()\n",
    "\n",
    "ss=StandardScaler() \n",
    "#feature scaling \n",
    "X_train=ss.fit_transform(X_train)\n",
    "X_test=ss.fit_transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "lr=LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "lr_pre=lr.predict(X_test)\n",
    "print(lr.score(X_test,y_test))\n",
    "print(classification_report(y_test,lr_pre,target_names=['Benign','Malignant']))\n",
    "sgdc=SGDClassifier(loss='log')\n",
    "sgdc.fit(X_train,y_train)\n",
    "sgdc_pre = sgdc.predict(X_test)\n",
    "print(sgdc.score(X_test,y_test))\n",
    "print((classification_report(y_test,sgdc_pre,target_names=['Benign','Malignant']))"
   ]
  }
 ]
}