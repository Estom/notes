### 一. 并发编程

#### 1.1 简介:

Java对多线程的封装类是Thread,  每一个Thread的实例都会通过JVM调用C++的方法, 和系统内核的线程做唯一的绑定, 因此, java中的多线程, 是真实的多线程, 可以利用多核系统的特性

但是Java从1997年诞生, 那时候还没有发展成多核机器, 因此Java在设计之初是没有考虑为多核多线程而设计的,  即使他后续推出了多线程编程, 但是相对来说依然还是挺复杂的

此外, Java的多线程中的线程栈空间初始大小为2兆, 那么2兆*1000 = 2G的内容, 所以, Java的多线程很吃内存, 这可不太好, 因为内存资源是很珍贵的



对于Go来说, 它诞生于09年, 那时多核机器已经问世, 它对适配多核, 在语言设计指出就有所考虑, 通过`goroutine`实现了多个函数之间的并发执行, 我们不再自己去写什么进程, 线程, 协程, 一个goroutine就够了

`goroutine`绑在着用户空间的线程, 通常只需要2k的内存就可以, 所以Go可以实现的高并发很容易就到达十万级别

#### 1.2 goroutine的使用

使用很简单, 只需要在func之前, 添加上go关键字就行

```go

func hello() {
	fmt.Println("Hello Goroutine!")
}
func main() {
	go hello()
	fmt.Println("main goroutine done!")
}
// 只会输出 main goroutine done! , 因为main goroutine执行结束之后, 就会结束, 子任务也被退出
```

* 解决方式1:

```go
// 可以简单粗暴的让main goroutine 睡一秒, 等待子任务的执行
func hello() {
	fmt.Println("Hello Goroutine!")
}
func main() {
	go hello()
	fmt.Println("main goroutine done!")
	time.Sleep(time.Second)
}
```



* 解决方式2: 使用 `sync.waitGroup`来实现同步

```go
var wait sync.WaitGroup

func hello() {
    // 减少一次计数
	defer wait.Done()
	fmt.Println("Hello Goroutine!")
}
func main() {

	for i:=0;i<=5;i++{
        // 每次启动一次, 就增加一次计数
		wait.Add(1)
		go hello()
	}
	// 当计数为0时, 不再wait
	wait.Wait()
	fmt.Println("main goroutine done!")
}
```



#### 1.3 goroutine的调度

goroutine的调度简称: GPM

一句话总结就是: P 管理着一组 G, 挂载到M上执行

* G: 就是goroutine本身, 还存放着goroutine和GPM之间绑定的信息
* P: P里面管理着一组goroutine, 存储当前goroutine的运行时环境, 函数指针, 堆栈, 地址边界,  同时 P会去对自己管理的goroutine队列进行调度,(  比如把占用CPU时间较长的goroutine暂停、运行后续的goroutine等等 , 当自己的队列中**消费完了goroutine就去全局的队列中取, 全局的goroutine队列也被消费完了, 就是其他队列里面抢**
*  M:（machine) 是Go运行时（runtime）对操作系统内核线程的虚拟， M与内核线程一般是一一映射的关系， 一个groutine最终是要放到M上执行的；



P与M一般也是一一对应的。他们关系是： P管理着一组G挂载在M上运行。当一个G长久阻塞在一个M上时，runtime会新建一个M，阻塞G所在的P会把其他的G 挂载在新建的M上。当旧的G阻塞完成或者认为其已经死掉时 回收旧的M。

P的个数是通过`runtime.GOMAXPROCS`设定（最大256），Go1.5版本之后默认为物理线程数。 在并发量大的时候会增加一些P和M，但不会太多，切换太频繁的话得不偿失。



* 单从线程调度讲，Go语言相比起其他语言的优势在于OS线程是由OS内核来调度的，`goroutine`则是由Go运行时（runtime）自己的调度器调度的，

* 调度器使用一个称为m:n调度的技术（复用/调度m个goroutine到n个OS线程）。 其一大特点是goroutine的调度是在用户态下完成的， 不涉及内核态与用户态之间的频繁切换，包括内存的分配与释放，都是在用户态维护着一块大的内存池， 不直接调用系统的malloc函数（除非内存池需要改变），成本比调度OS线程低很多。 
* 充分利用了多核的硬件资源，近似的把若干goroutine均分在物理线程上， 再加上本身goroutine的超轻量，以上种种保证了go调度方面的性能。



#### 1.4 GOMAXPROCS

Go运行时的调度器使用`GOMAXPROCS`参数来确定需要使用多少个OS线程来同时执行Go代码。默认值是机器上的CPU核心数。例如在一个8核心的机器上，调度器会把Go代码同时调度到8个OS线程上（GOMAXPROCS是m:n调度中的n）

**Go语言中可以通过`runtime.GOMAXPROCS()`函数设置当前程序并发时占用的CPU逻辑核心数。**

**Go1.5版本之前，默认使用的是单核心执行。Go1.5版本之后，默认使用全部的CPU逻辑核心数。**

我们可以通过将任务分配到不同的CPU逻辑核心上实现并行的效果，这里举个例子

```go
func main() {
	runtime.GOMAXPROCS(1)
	go a()
    go a()
    go a()
}
```



### 二 . channel

#### 2.01 channel 简介:

在Java中, JMM规范要求, 如果两条线程之间想通信的话, 需要借助于主存中的变量区完成通信

**在Go中,  两个并发执行的函数可以通过channel进行数据的交互**

Go的并发模型是`CSP (communicating  sequential processor)` 即, 通过通信来共享内存, 而不是通过内存来实现通信 

在Go中, 通过channel去实现各个goroutine之间的通信, chanel是一个特殊类型, 遵循先进先出 (FIFO)的规则, 保证收发信息的顺序, 每一个channel都有他具体的类型, 声明通道时, 需要指定这个类型



#### 2.02 channel的类型

```go
var ch1 chan int
var ch2 chan string
var ch3 chan bool
var ch4 chan []int
...
```



#### 2.03 创建通道

通道声明后, **还得为他分配空间才能使用**

可以通过make函数设置通道缓冲区的大小

```go
func main() {
	var ch chan int
	ch4 := make(chan int)
	ch5 := make(chan bool)
	ch6 := make(chan []int)
	ch7 := make(chan []int,15)

	fmt.Println(ch) // <nil>
	fmt.Println(ch4) // <0xc00001a120>
	fmt.Println(ch5) // <0xc00001a180>
	fmt.Println(ch6) // <0xc00001a1e0>
	fmt.Println(ch7) // <0xc00003e060>
}
```

#### 2.04 channel的操作

```go
// 创建
ch := make(chan int ,15)
// 将值写入通道:
ch <- 10

// 取出存储value中
value := <- ch

// 取出并忽略
<- ch

// 关闭通道, 只有在通知接收方所有的数据都发送完毕的时候, 才需要关闭通道
// 通道是可以被强制回收的, 所以不一定非得关闭通道
close(ch)
```



#### 2.05 有缓冲的channel

当缓冲信道达到满的状态的时候，就会表现出阻塞了，因为这时再也不能承载更多的数据了，「你们必须把 数据拿走，才可以流入数据」。

在声明一个信道的时候，我们给make以第二个参数来指明它的容量(默认为0，即无缓冲):

```go
 // 写入2个元素都不会阻塞当前goroutine, 存储个数达到2的时候会阻塞
 // 如果被阻塞后, 还有没其他的goroutine去消费这个channel, 就会爆出死锁
var ch chan int = make(chan int, 2)
```

如下的例子，缓冲信道ch可以无缓冲的流入3个元素: 

```go
func main() {
    ch := make(chan int, 3)
    ch <- 1
    ch <- 2
    ch <- 3
}
```

如果你再试图流入一个数据的话，信道ch会阻塞main线, 报死锁。

也就是说，缓冲信道会在满容量的时候加锁。

其实，缓冲信道是先进先出的，我们可以把缓冲信道看作为一个线程安全的队列：

```go
func main() {
    ch := make(chan int, 3)
    ch <- 1
    ch <- 2
    ch <- 3

    fmt.Println(<-ch) // 1
    fmt.Println(<-ch) // 2
    fmt.Println(<-ch) // 3
}
```





```go
// 缓冲区大小是15的通道
ch7 := make(chan []int,15)

func main() {
	ch := make(chan int,3)
	for i:=3;i<8 ;i++  {
		ch <-i
	}
}

// 向有缓冲区的通道中, 只存入, 当超出缓冲区大小的容量时, 就会报错 死锁
fatal error: all goroutines are asleep - deadlock!
goroutine 1 [chan send]:
main.main()
```



#### 2.06 无缓冲区的channel

如下:

```go
	// 没有缓冲区的通道
    ch6 := make(chan []int)
```



例: 当向没有缓冲区的channel写入数据,  同时也没有其他的goroutine去尝试获取锁,  就会报错死锁

>  **因为我们使用`ch := make(chan int)`创建的是无缓冲的通道，无缓冲的通道只有在有人接收值的时候才能发送值。**

```go
func main() {
	ch := make(chan int)
	ch <- 10
}

fatal error: all goroutines are asleep - deadlock!
goroutine 1 [chan send]:
main.main()


// 可以向下面这样, 找个goroutine去消费它
func hello(ch <-chan int) {
	var value = <- ch
	fmt.Println("value: ",value)
}

func main() {
	 ch := make(chan int)
	 go hello(ch)
	 ch <- 10
}
```

无缓冲的信道永远不会存储数据，只负责数据的流通 

* 从无缓冲信道取数据，必须要有数据流进来才可以，否则当前线阻塞 
* 数据流入无缓冲信道, 如果没有其他goroutine来拿走这个数据，那么当前线阻塞 



#### 2.07 无缓冲信道的数据进出顺序

我们已经知道，无缓冲信道从不存储数据，流入的数据必须要流出才可以 

```go
var ch chan int = make(chan int)

func foo(id int) { //id: 这个routine的标号
    ch <- id
}

func main() {
    // 开启5个routine
    for i := 0; i < 5; i++ {
        go foo(i)
    }

    // 取出信道中的数据
    for i := 0; i < 5; i++ {
        fmt.Print(<- ch)
    }
}
```

我们开了5个goroutine，然后又依次取数据。其实整个的执行过程细分的话，5个线的数据 依次流过信道ch, main打印之, 而宏观上我们看到的即 无缓冲信道的数据是先到先出，但是 无缓冲信道并不存储数据，只负责数据的流通 







#### 2.08 体会从空channel中获取值会被阻塞

示例1:

```go
// 可以向下面这样, 找个goroutine去消费它
func hello(ch <-chan int) {
	fmt.Println("准备获取值 value: ")
	var value = <- ch // 被阻塞住,等到main往channel中存入值
	fmt.Println("value: ",value)
}

func main() {
	ch := make(chan int)
	go hello(ch)

	time.Sleep(time.Second*5)
	ch <- 10
	time.Sleep(time.Second*5)
}
```

示例2: 

```go
var complete chan int = make(chan int)

func loop() {
    for i := 0; i < 10; i++ {
        fmt.Printf("%d ", i)
    }

    complete <- 0 // 执行完毕了，发个消息
}


func main() {
    go loop()
    <- complete // 直到线程跑完, 取到消息. main在此阻塞住
}
```



> 默认的，信道的存消息和取消息都是阻塞的 (叫做无缓冲的信道，不过缓冲这个概念稍后了解，先说阻塞的问题)。
>
> 也就是说, 无缓冲的信道在取消息和存消息的时候都会挂起当前的goroutine，除非另一端已经准备好。

#### 2.09 for range从通道循环取值

* 如果通道已经关闭了, 还往里面写入值, 就会爆出 panic
* for range 可以自动判断channel是否关闭了, 当 channel 关闭后, for range也会自动退出, 这是普遍的做法



```go
func main() {
	ch1 := make(chan int)
	ch2 := make(chan int)

	go func() {
		for i := 0; i < 100; i++ {
			ch1 <- i
		}
		// todo 发送完毕后, 关闭channel
		close(ch1)
	}()

	go func() {
		for {
			// todo channel 关闭后, 得到的ok = false
			v, ok := <-ch1
			if !ok {
				break
			}
			ch2 <- v * v
		}
		// 关闭channel
		close(ch2)
	}()

	// todo 通常使用 for range 去遍历channel, channel关闭后, 会自动退出
	for value := range ch2 {
		fmt.Println(value)
	}
}
```



#### 2.10 单向通道

首先得知道, 一个通道, 它既可以被写, 也可以被读 

但是, 我们可以限制什么情况下它只能被写, 什么情况下只能被读

就比如下面的例子, 通道 ch , 默认的可以对ch进行读写, 也可以像下面那样, 限制` inChannel`函数,  只能往通道里面写,  限制 outerChannel函数,  只能从通道里面读

```go
// 只能往里面写的通道如下:
func inChannel(ch chan<- int){
	ch <- 10
    close(ch)
}

// 只能往外读
func outerChannel( ch  <-chan int){
    v:= <- ch
    close(ch)
}

```

#### 2.11 worker pool

worker pool 实际上就是 goroutine 池 ,  

```go
// 开启指定数量的 goroutine
func worker(number int, jobs <-chan int, results chan<- int) {
	for i:=1;i<=number;i++{
		go func(i int) {
			for j := range jobs {
				fmt.Printf("worker:%d start job:%d\n", i, j)
				time.Sleep(time.Second)
				fmt.Printf("worker:%d end job:%d\n", i, j)
				results <- j * 2
			}
		}(i)
	}
}

func main() {
	jobs := make(chan int, 100)
	results := make(chan int, 100)
	// 开启3个goroutine
	worker(3, jobs, results)
	// 添加5个任务
	for j := 1; j <= 5; j++ {
		jobs <- j
	}
	close(jobs)
	time.Sleep(time.Second*6)
}

```



#### 2.12 select

Go内置了select 关键字, 可以同时监听多个channel, 在接收和发送的过程中同样会发生阻塞等待 



```go
select{
    case <-ch1:
        ...
    case data := <-ch2:
        ...
    case ch3<-data:
        ...
    default:
        默认操作
}

示例: 
func main() {
	ch1 := make(chan int)
	ch2 := make(chan int)
	select{
	case value1:=<-ch1:
		fmt.Println("ch1",value1)
	case value2 := <-ch2:
		fmt.Println("ch2",value2)
	default:
		fmt.Println("default")
	}
}
//结果:
default


// 示例2
func main() {
	ch1 := make(chan int,1)
	ch2 := make(chan int,1)
	ch1 <- 10
	ch2 <- 10

	select{
	case value1:=<-ch1:
		fmt.Println("ch1",value1)
	case value2 := <-ch2:
		fmt.Println("ch2",value2)
	default:
		fmt.Println("default")
	}
}
结果:
ch1 10



// 示例3: 
func main() {
	ch1 := make(chan int,1)
	ch2 := make(chan int,1)
	ch3 := make(chan int,1)
	ch4 := make(chan int,1)
	ch5 := make(chan int,1)
	ch6 := make(chan int,1)
	ch7 := make(chan int,1)
	ch1 <- 10
	ch2 <- 10
	ch3 <- 10
	ch4 <- 10
	ch5 <- 10
	ch6 <- 10
	ch7 <- 10

	for i:=1;i<=8 ;i++  {
		select{
		case value1:=<-ch1:
			fmt.Println("ch1",value1)
		case value2 := <-ch2:
			fmt.Println("ch2",value2)
		case value2 := <-ch3:
			fmt.Println("ch3",value2)
		case value2 := <-ch4:
			fmt.Println("ch4",value2)
		case value2 := <-ch5:
			fmt.Println("ch5",value2)
		case value2 := <-ch6:
			fmt.Println("ch6",value2)
		case value2 := <-ch7:
			fmt.Println("ch7",value2)
		default:
			fmt.Println("default")
		}
	}
}

// 结果: 表名 select会随机选中case进行处理
ch2 10
ch6 10
ch5 10
ch7 10
ch3 10
ch4 10
ch1 10
default


// 示例4: 
func main() {
	ch1 := make(chan int,1)
	ch2 := make(chan int,1)
	ch1 <- 10
	ch2 <- 10

	for i:=1;i<=3 ;i++  {
		select{
		case value1:=<-ch1:
			fmt.Println("ch1",value1)
			time.Sleep(time.Second*5)
		case value2 := <-ch2:
			fmt.Println("ch2",value2)
		default:
			fmt.Println("default")
		}
	}
}
// 证明, 任意一个case出现阻塞的情况, 整个select 都被阻塞
```

select的好处:

* 可处理一个或多个channel的发送/接收操作。
* 如果多个`case`同时满足，`select`会随机选择一个。
* 对于没有`case`的`select{}`会一直等待，可用于阻塞main函数 





### 三. 并发和并行

什么是并发, 什么是并行? 

简单举例来说:

* 两个队列，一个Coffee机器，那是并发
* 两个队列，两个Coffee机器，那是并行

说白了其实就是如果我们的电脑只有一个CPU,  那最多只能做到并发 , 而 如果我们的电脑本身就是多核的,  多个CPU之间可以做大并行执行 , 那我们的go程序就可以变成并行

看这个示例: 

```go
var quit chan int = make(chan int)

func loop() {
	for i := 0; i < 10; i++ {
		fmt.Printf("%d ", i)
	}
	quit <- 0
}

func main() {
    // 在go1.5之前, 默认是1
	runtime.GOMAXPROCS(1) // 最多使用2个核
	// 开两个goroutine跑函数loop, loop函数负责打印10个数
	go loop()
	go loop()

	for i := 0; i < 2; i++ {
		<-quit
	}
}

```



如果将GOMAXPROCES设置值>1 , 则会出现争抢执行的效果 (go 1.5之后, 默认的GOMAXPROCES值才是 机器的最大的核心数) , 且, 只有当GOMAXPROCS设置的值大于1时, 才可能是真正的并行运行



还可以像这样, 显示的让CPU让出执行的时间

```go
func loop() {
    for i := 0; i < 10; i++ {
        runtime.Gosched() // 显式地让出CPU时间给其他goroutine
        fmt.Printf("%d ", i)
    }
    quit <- 0
}


func main() {

    go loop()
    go loop()

    for i := 0; i < 2; i++ {
        <- quit
    }
}
结果:
0 0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9
```



### 四. runtime 调度器

* Gosched: 让当前goroutine让出cpu
* NumCPU: 返回当前系统的CPU核心数
* GOMAXPROCS: 设置当前可同时使用的CPU数
* Goexit: 退出当前goroutine , 但是 defer 依然会正常执行





### 五. 并发安全和锁

多个goroutine 操作同一个数据, 如果不加锁, 很容易出现并发异常, 导致数据不准确, 和Java一样, Go也提供了一些列的锁用来同步各个goroutine的计算过程



#### 5.1 互斥锁

出现线程安全的demo

```go
var wait sync.WaitGroup

var x int

func add() {
	for i := 1; i <= 5000; i++ {
		x++
	}
	wait.Done()
}

func main() {

	wait.Add(2)
	go add()
	go add()
	wait.Wait()
	fmt.Println(x) // 7656
}
```

解决:  互斥锁`sync.Mutex` 它的用法和java中的ReentranLock相仿, 示例如下

```go
var wait sync.WaitGroup
var lock sync.Mutex

var x int

func add() {
	for i := 1; i <= 5000; i++ {
        lock.lock()
		x++
        lock.unlock()
	}
	wait.Done()
}

func main() {

	wait.Add(2)
	go add()
	go add()
	wait.Wait()
	fmt.Println(x) // 7656
}
```

> **使用 sync.Mutex 加锁, 被唤醒的几率是随机的**



#### 5.2 读写锁

Go提供的读写锁是 `sync.RWMutex`

遵循: 

* 读读不互斥
* 读写互斥
* 写写互斥

> 需要注意的是读写锁非常适合读多写少的场景，如果读和写的操作差别不大，读写锁的优势就发挥不出来。 



#### 5.3 几个死锁的例子

1. 只在单一的goroutine里操作无缓冲信道，一定死锁。比如你只在main函数里操作信道: 

```go
func main() {
    ch := make(chan int)
    ch <- 1 // 1流入信道，堵塞当前线, 没人取走数据信道不会打开
    fmt.Println("This line code wont run") //在此行执行之前Go就会报死锁
}
```

1. 如下也是一个死锁的例子: 

其中主线等ch1中的数据流出，ch1等ch2的数据流出，但是ch2等待数据流入，两个goroutine都在等，也就是死锁。 

```go
var ch1 chan int = make(chan int)
var ch2 chan int = make(chan int)

func say(s string) {
    fmt.Println(s)
    ch1 <- <- ch2 // ch1 等待 ch2流出的数据
}

func main() {
    go say("hello")
    <- ch1  // 堵塞主线
}
```

1. 总结来看，为什么会死锁？非缓冲信道上如果发生了流入无流出，或者流出无流入，也就导致了死锁。或者这样理解 Go启动的所有goroutine里的非缓冲信道一定要一个线里存数据，一个线里取数据，要成对才行 。所以下面的示例一定死锁: 

```go
c, quit := make(chan int), make(chan int)

go func() {
   c <- 1  // c通道的数据没有被其他goroutine读取走，堵塞当前goroutine
   quit <- 0 // quit始终没有办法写入数据
}()

<- quit // quit 等待数据的写
```





#### 5.4 sync.WaitGroup

我们一般都是使用它去防止main goroutine提前终止, 而中断子 goroutine

他的作用和Java中的CountDownLatch相仿

| 方法名                          | 功能                |
| ------------------------------- | ------------------- |
| (wg * WaitGroup) Add(delta int) | 计数器+delta        |
| (wg *WaitGroup) Done()          | 计数器-1            |
| (wg *WaitGroup) Wait()          | 阻塞直到计数器变为0 |

#### 5.5 sync.Once

编程的很多场景下我们需要确保某些操作在高并发的场景下只执行一次，例如只加载一次配置文件、只关闭一次通道等。

`sync.Once`只有一个`Do`方法，其签名如下：

```go
func (o *Once) Do(f func()) {}
```

实例如下: 只会打印一次 hi

```go
var once sync.Once

func add() {
	for i := 1; i <= 5000; i++ {
		once.Do(func() {
			fmt.Println("hi")
		})
	}
	wait.Done()
}

func main() {
	wait.Add(2)
	go add()
	go add()
	go add()
	go add()
	go add()
	wait.Wait()
}
```



#### 5.6 单例模式

借助`sync.Once`的特性去做这件事

```go
type singleton struct {
	name string
} 
var once sync.Once
var instance *singleton

func getInstance()(*singleton){
	once.Do(func() {
		instance = &singleton{name:"tom"}
	})
	return instance
}
```



#### 5.7 sync.Map

Go语言中提供的原生map是不能保证并发安全的,  在sync包中的Map可以保证并发安全的特性

sync.Map 内置了诸如: `Store , Load , LoadOrStore , Delete , Range` 方法, 都可以保证线程安全



#### 5.8 原子操作

Demo

```go
// 导入原子类相关的包
import (
	"fmt"
	"sync/atomic"
)

func main() {
    // 注意这里不能写 index := 1 , 因为下loadInt32, 编译都过不去
    index := int32(1)
    // 传递地址
	loadInt32 := atomic.LoadInt32(&index)
    // 添加的动作也是传递地址
	atomic.AddInt32(&loadInt32,1)
	fmt.Println(loadInt32)
}

```

* atomic常用的API如下: 

```go
// 加载一个原子类型的数  loadXXX
func LoadInt32(addr *int32) (val int32)
func LoadInt64(addr *int64) (val int64)
func LoadUint32(addr *uint32) (val uint32)
func LoadUint64(addr *uint64) (val uint64)
func LoadUintptr(addr *uintptr) (val uintptr)
func LoadPointer(addr *unsafe.Pointer) (val unsafe.Pointer)

// 写入操作, 它会对原有的值进行一次覆盖
func StoreInt32(addr *int32, val int32)
func StoreInt64(addr *int64, val int64)
func StoreUint32(addr *uint32, val uint32)
func StoreUint64(addr *uint64, val uint64)
func StoreUintptr(addr *uintptr, val uintptr)
func StorePointer(addr *unsafe.Pointer, val unsafe.Pointer)

// 累加 
func AddInt32(addr *int32, delta int32) (new int32)
func AddInt64(addr *int64, delta int64) (new int64)
func AddUint32(addr *uint32, delta uint32) (new uint32)
func AddUint64(addr *uint64, delta uint64) (new uint64)
func AddUintptr(addr *uintptr, delta uintptr) (new uintptr)

// 交换值
func SwapInt32(addr *int32, new int32) (old int32)
func SwapInt64(addr *int64, new int64) (old int64)
func SwapUint32(addr *uint32, new uint32) (old uint32)
func SwapUint64(addr *uint64, new uint64) (old uint64)
func SwapUintptr(addr *uintptr, new uintptr) (old uintptr)
func SwapPointer(addr *unsafe.Pointer, new unsafe.Pointer) (old unsafe.Pointer)

// CAS 比较+交换
func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool)
func CompareAndSwapInt64(addr *int64, old, new int64) (swapped bool)
func CompareAndSwapUint32(addr *uint32, old, new uint32) (swapped bool)
func CompareAndSwapUint64(addr *uint64, old, new uint64) (swapped bool)
func CompareAndSwapUintptr(addr *uintptr, old, new uintptr) (swapped bool)
func CompareAndSwapPointer(addr *unsafe.Pointer, old, new unsafe.Pointer) (swapped bool)
```



#### 5.9 Cond

条件等待Conｄ

示例：

```go
func main() {
	condition:=false

	var lock sync.Mutex
	cond:=sync.NewCond(&lock)

	go func() {
		lock.Lock()
		condition=true
		// 模拟其他耗时操作
		time.Sleep(time.Second*3)
		// 通过signal使得
		cond.Signal()
		lock.Unlock()
	}()

	
	/*	
	    官方要求的写法
		c.L.Lock()
		for !condition() {
		    c.Wait()
		}
		// 执行条件满足之后的动作...
		c.L.Unlock()
	*/
	
	lock.Lock()
	// 为了防止虚假唤醒, wait放置到条件循环中
	for !condition{
		cond.Wait()
	}
	fmt.Println("条件满足, 开始后续的动作")
	lock.Unlock()

}
```

文档：

```go
type Cond struct {
    L Locker // 在“检查条件”或“更改条件”时 L 应该锁定。
}
 
// 创建一个条件等待
func NewCond(l Locker) *Cond
 
// Broadcast 唤醒所有等待的 Wait，建议在“更改条件”时锁定 c.L，更改完毕再解锁。
func (c *Cond) Broadcast()
 
// Signal 唤醒一个等待的 Wait，建议在“更改条件”时锁定 c.L，更改完毕再解锁。
func (c *Cond) Signal()
 
// Wait 会解锁 c.L 并进入等待状态，在被唤醒时，会重新锁定 c.L
func (c *Cond) Wait()
```



### 六. Pool 临时对象池

```go

type Pool struct {
    noCopy noCopy
 
    local     unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal
    localSize uintptr        // size of the local array
 
    // New optionally specifies a function to generate
    // a value when Get would otherwise return nil.
    // It may not be changed concurrently with calls to Get.
    New func() interface{}
}
 
 
// Local per-P Pool appendix.
type poolLocalInternal struct {
    private interface{}   // Can be used only by the respective P.
    shared  []interface{} // Can be used by any P.
    Mutex                 // Protects shared.
}
 
type poolLocal struct {
    poolLocalInternal
 
    // Prevents false sharing on widespread platforms with
    // 128 mod (cache line size) = 0 .
    pad [128 - unsafe.Sizeof(poolLocalInternal{})%128]byte
}
```

Pool 用于存储临时对象，它将使用完毕的对象存入对象池中，在需要的时候取出来重复使用，目的是为了避免重复创建相同的对象造成 GC 负担过重。其中存放的临时对象随时可能被 GC 回收掉（如果该对象不再被其它变量引用） 



从 Pool 中取出对象时，如果 Pool 中没有对象，将返回nil，但是如果给 Pool.New 字段指定了一个函数的话，Pool 将使用该函数创建一个新对象返回。



 Pool 可以安全的在多个例程中并行使用，但 Pool 并不适用于所有空闲对象，Pool 应该用来管理并发的例程共享的临时对象，而不应该管理短寿命对象中的临时对象，因为这种情况下内存不能很好的分配，这些短寿命对象应该自己实现空闲列表。Pool 在开始使用之后，不能再被复制。



Pool是提供给外部使用的对象。其中的local成员的真实类型是一个poolLocal数组，localSize是数组长度。poolLocal是真正保存数据的地方。priveate保存了一个临时对象，shared是保存临时对象的数组。　　



为什么Pool中需要这么多poolLocal对象呢？实际上，Pool是给每个线程分配了一个poolLocal对象。也就是说local数组的长度，就是工作线程的数量(size := runtime.GOMAXPROCS(0))。当多线程在并发读写的时候，通常情况下都是在自己线程的poolLocal中存取数据。当自己线程的poolLocal中没有数据时，才会尝试加锁去其他线程的poolLocal中“偷”数据。

```go
func (p *Pool) Get() interface{} {
    if race.Enabled {
        race.Disable()
    }
    l := p.pin()    //获取当前线程的poolLocal对象，也就是p.local[pid]。
    x := l.private
    l.private = nil
    runtime_procUnpin()
    if x == nil {
        l.Lock()
        last := len(l.shared) - 1
        if last >= 0 {
            x = l.shared[last]
            l.shared = l.shared[:last]
        }
        l.Unlock()
        if x == nil {
            x = p.getSlow()
        }
    }
    if race.Enabled {
        race.Enable()
        if x != nil {
            race.Acquire(poolRaceAddr(x))
        }
    }
    if x == nil && p.New != nil {
        x = p.New()
    }
    return x
}
```

为什么这里要锁住。答案在getSlow中。因为当shared中没有数据的时候，会尝试去其他的poolLocal的shared中偷数据。Pool.Get的时候，首先会在local数组中获取当前线程对应的poolLocal对象。如果private中有数据，则取出来直接返回。如果没有则先锁住shared，有数据则直接返回。 



Go语言的goroutine虽然可以创建很多，但是真正能物理上并发运行的goroutine数量是有限的，是由runtime.GOMAXPROCS(0)设置的。所以这个Pool高效的设计的地方就在于将数据分散在了各个真正并发的线程中，每个线程优先从自己的poolLocal中获取数据，很大程度上降低了锁竞争。 



### 七. 正确使用锁的八个注意点

1. 尽量减少锁的持有时间，毕竟使用锁是有代价的，通过减少锁的持有时间来减轻这个代价： 

* 细化锁的粒度。通过细化锁的粒度来减少锁的持有时间以及避免在持有锁操作的时候做各种耗时的操作。
* 不要在持有锁的时候做 IO 操作。尽量只通过持有锁来保护 IO 操作需要的资源而不是 IO 操作本身： 

```go

func doSomething() {
    m.Lock()
    item := ...
    http.Get()  // 各种耗时的 IO 操作
    m.Unlock()
}
 
// 改为
func doSomething() {
    m.Lock()
    item := ...
    m.Unlock()
 
    http.Get()
}
```





2. 善用 defer 来确保在函数内正确释放了锁

尤其是在那些内部有好几个通过 if err != nil 判断来提前返回的函数中，通过 defer 可以确保不会遗漏释放锁操作，避免出现死锁问题，以及避免函数内非预期的 panic 导致死锁的问题： 

```go
func doSomething() {
    m.Lock()
    defer m.Unlock()
 
    err := ...
    if err != nil {
        return
    }
 
    err = ...
    if err != nil {
        return
    }
 
    ...
    return
}
```

3. 不过使用 defer 的时候也要注意别因为习惯性的 defer m.Unlock() 导致无意中在持有锁的时候做了 IO 操作，出现了非预期的持有锁时间太长的问题。 

```go
// 非预期的在持有锁期间做 IO 操作
func doSomething() {
    m.Lock()
    defer m.Unlock()
 
    item := ...
    http.Get()  // 各种耗时的 IO 操作
}
```



4. copy 结构体操作可能导致非预期的死锁

copy 结构体时，如果结构体中有锁的话，记得重新初始化一个锁对象，否则会出现非预期的死锁： 

```go
type User struct {
	sync.Mutex

	name string
}

func main() {
	u1 := &User{name: "test"}
	u1.Lock()
	defer u1.Unlock()

	tmp := *u1 // 取出u1的值
	u2 := &tmp // 将指向u1的指针赋值给u2 , 实现结构体的拷贝
	// u2.Mutex = sync.Mutex{} // 没有这一行就会死锁

	fmt.Printf("%#p\n", u1)
	fmt.Printf("%#p\n", u2)

	u2.Lock()
	defer u2.Unlock()
}
```



5. build/test 时使用 -race 参数以便运行时检测数据竞争问题

可以在执行 go build 或 go test 时增加一个 -race 参数来开启数据竞争检测功能，通过这种方式来实现在本地开发环境/CI/测试环境阶段发现程序中可能存在的数据竞争问题： 

```go
type Todo struct {
    sync.Mutex
 
    tasks []string
}
 
func (t *Todo) do() {
    for _, task := range t.tasks {
        fmt.Println(task)
    }
}
 
func (t *Todo) Add(task string) {
    t.Lock()
    defer t.Unlock()
 
    t.tasks = append(t.tasks, task)
}
 
func main() {
    t := &Todo{}
 
    for i := 0; i < 2; i++ {
        go t.Add(fmt.Sprintf("%d", i))
    }
    for i := 0; i < 2; i++ {
        t.do()
    }
}


/////////
$ go build -race -o main .
$
$ ./main
==================
WARNING: DATA RACE
Read at 0x00c0000a0048 by main goroutine:
  main.(*Todo).do()
      /Users/xxx/tmp/golang/race/main.go:15 +0x42
  main.main()
      /Users/xxx/tmp/golang/race/main.go:34 +0x154

Previous write at 0x00c0000a0048 by goroutine 6:
  main.(*Todo).Add()
      /Users/xxx/tmp/golang/race/main.go:24 +0x11d

Goroutine 6 (finished) created at:
  main.main()
      /Users/xxx/tmp/golang/race/main.go:31 +0x127
==================
0
==================
WARNING: DATA RACE
Read at 0x00c0000b0010 by main goroutine:
  main.(*Todo).do()
      /Users/xxx/tmp/golang/race/main.go:15 +0x85
  main.main()
      /Users/xxx/tmp/golang/race/main.go:34 +0x154

Previous write at 0x00c0000b0010 by goroutine 7:
  main.(*Todo).Add()
      /Users/xxx/tmp/golang/race/main.go:24 +0xe3

Goroutine 7 (finished) created at:
  main.main()
      /Users/xxx/tmp/golang/race/main.go:31 +0x127
==================
1
0
1
Found 2 data race(s)
```



6. 使用 go-deadlock 检测死锁或锁等待问题

上面说的在持有锁的时候做 IO 操作或其他非预期的耗时超时的问题，一方面需要在写程序的时候注意一下，另一方面也有可能是无意中代入进去的（比如上面提到的习惯性 defer 导致的）。对于那些无意中代入进去的锁等待的问题人为的去 review 的话通常很难发现，此时就需要用工具来检测了。恰好有一个叫 [go-deadlock](https://github.com/sasha-s/go-deadlock) 的工具可以实现这个功能。 '

```go
import (
    "net/http"
    "time"
 
    sync "github.com/sasha-s/go-deadlock"
)
 
var mu sync.Mutex
var url = "http://baidu.com:90"
 
func do() {
    mu.Lock()
    defer mu.Unlock()
 
    u := url
    http.Get(u)  // 非预期的在持有锁期间做 IO 操作，导致锁等待时间变长
}
 
func main() {
    // 检测超过 100 ms 的锁等待
    sync.Opts.DeadlockTimeout = time.Millisecond * 100
 
    var wg sync.WaitGroup
    for i := 0; i < 3; i++ {
        wg.Add(1)
        go func() {
            defer wg.Done()
            do()
        }()
    }
 
    wg.Wait()
}

/////////////////////////
$ go run main.go
POTENTIAL DEADLOCK:
Previous place where the lock was grabbed
goroutine 36 lock 0x1483b90
main.go:14 main.do { mu.Lock() } <<<<<
main.go:30 main.main.func1 { do() }

Have been trying to lock it again for more than 100ms
goroutine 35 lock 0x1483b90
main.go:14 main.do { mu.Lock() } <<<<<
main.go:30 main.main.func1 { do() }

Here is what goroutine 36 doing now
goroutine 36 [select]:
net/http.(*Transport).getConn(0x14616c0, 0xc00015e150, 0x0, 0x128adb3, 0x4, 0xc000014100, 0xc, 0x0, 0x0, 0xc0000559e8)
    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:1004 +0x58e
net/http.(*Transport).roundTrip(0x14616c0, 0xc000160000, 0x203000, 0xc000055c90, 0x11d823a)
    /usr/local/Cellar/go/1.11/libexec/src/net/http/transport.go:451 +0x690
net/http.(*Transport).RoundTrip(0x14616c0, 0xc000160000, 0x14616c0, 0x0, 0x0)
    /usr/local/Cellar/go/1.11/libexec/src/net/http/roundtrip.go:17 +0x35
net/http.send(0xc000160000, 0x12c78a0, 0x14616c0, 0x0, 0x0, 0x0, 0xc00000e030, 0x1708000, 0xc000055d20, 0x1)
    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:250 +0x14b
net/http.(*Client).send(0x1466200, 0xc000160000, 0x0, 0x0, 0x0, 0xc00000e030, 0x0, 0x1, 0x0)
    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:174 +0xfa
net/http.(*Client).do(0x1466200, 0xc000160000, 0x0, 0x0, 0x0)
    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:641 +0x2a8
net/http.(*Client).Do(0x1466200, 0xc000160000, 0x128adb3, 0x13, 0x0)
    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:509 +0x35
net/http.(*Client).Get(0x1466200, 0x128adb3, 0x13, 0xc0000220c0, 0x12412c0, 0xc000055f80)
    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:398 +0x9d
net/http.Get(0x128adb3, 0x13, 0x1483b90, 0x0, 0xc000114fb8)
    /usr/local/Cellar/go/1.11/libexec/src/net/http/client.go:370 +0x41
main.do()
    /Users/xxx/tmp/golang/deadlock/main.go:18 +0x75
main.main.func1(0xc00009c3f4)
    /Users/xxx/tmp/golang/deadlock/main.go:30 +0x48
created by main.main
    /Users/xxx/tmp/golang/deadlock/main.go:28 +0x83

exit status 2
```



7. 使用go mutux实现 tryLock功能: <https://colobu.com/2017/03/09/implement-TryLock-in-Go/> 



8. 改为使用 channel

有些时候可能使用 channel 会更符合需求，对于这些更适合 channel 的场景可以改为使用 channel 而不是 lock  