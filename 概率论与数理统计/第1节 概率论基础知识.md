# 1 概率论的基本概念

## 1.1 随机事件
* 样本空间$S$：将随机实验所有可能的记过组成的集合称为样本空间。
* 样本点：样本空间的每个结果称为样本点。
* 随机试验、随机事件$E$、基本事件、必然事件、不可能事件、对立事件$A\overline{A}$、古典概型。

## 1.2 频率与概率

* 频率：在相同的条件下进行$n$次实验，事件$A$发生的次数$n_A$称为事件$A$发生的频数。$\frac{n_A}{n}$称为事件$A$发生的频率。
* 概率：$E$是随机试验，$S$是样本空间。$P(A)$称为事件$A$的概率。
* 频率与概率的性质：
  * 非负性：$P(A)>0$
  * 规范性：$P(S)=1$
  * 可列可加性：$A_iA_j=\emptyset,P(A_1\cup A_2\cup\dotsm\cup P_n)=P(A_1)+P(A_2)+\dotsm+P(A_n)$

## 1.3 条件概率

### 定义  
设$A,B$是两个事件，且$P(A)>0$,则称
$$
P(B|A)=\frac{P(AB)}{P(A)}
$$
也是一种链式法则。图解的方式理解。
$$
P(B|A)=\frac{P(AB|1)}{P(A|1)}
$$
在事件A发生的条件下，事件B发生的概率。

### 性质
* 非负性
* 规范性
* 可列可加性。

### 乘法定理
$$
P(AB)=P(A)P(B|A)
$$
也是一种链式法则。图解的方式理解。
$$
P(AB|1)=P(A|1)P(B|A)
$$

### 全概率公式  
设试验$E$样本空间为$S$，$A$为试验的实践，$B_1,\dotsm,B_n$为S的一个划分，且$P(B_i)>0$,则：
$$
P(A)=P(A|B_1)P(B_1)+\dotsm+P(A|B_n)P(B_n)\\
=\sum_i^nP(A|B_i)P(B_i)
$$

### 贝叶斯公式
设试验$E$样本空间为$S$，$A$为试验的实践，$B_1,\dotsm,B_n$为S的一个划分，且$P(A)>0,P(B_i)>0$,则：
$$
P(B_i|A)=\frac{P(A|B_i)P(B_i)}{\sum_{j=1}^nP(A|B_j)P(B_j)}
$$
> 起到了交换条件与结果的作用。
## 1.4 独立性
### 定义
如果A，B是两个事件，满足：
$$
P(AB)=P(A)P(B)
$$
则称事件A，B相互独立。即事件A的发生对事件B没有影响。

### 定理一
若A，B相互独立，则$P(B|A)=P(B)$.

### 定理二
若A，B相互独立，则下列事件也相互独立：
$$
A\overline{B},\overline{A}B,\overline{A}\overline{B}
$$



# 2 随机变量的分布

## 2.1 随机变量

### 定义  
样本空间$S={e}$,$X=X(e)$是定义在样本空间上的实值单值函数，称$X=X(e)$为随机变量。

## 2.2 离散型随机变量及其概率分布

### 定义  
随机变量的取值是有限个或者无限多个。随机变量$X$所有可能的取值为$x_k$,随机变量的分布律记为：
$$
P(X=x_k)=P_k,k=1,2,3,\dotsm
$$

### 性质  
1. $P_k\geq 0$
2. $\sum P_k=1$

### 分布律
1. 表格形式给出每个随机变量的分布律。
2. 代数公式表示随机变量的分布律。

### 01分布  
$$
P(X=k)=p^k(1-p)^{1-k},k=0,1
$$

### 伯努利实验-二项分布$X\sim b(n,p)$：  
X表示n重伯努利实验事件A发生的次数。
$$
P(X=k)=C_n^kp^k(1-p)^{n-k},k=0,1,\dotsm,n
$$


### 泊松分布$X\sim \pi (\lambda)$：
$$
P(X=k)=\frac{\lambda ^ke^{-\lambda}}{k!},k=1,2,\dotsm,
$$

### 泊松定理（用泊松分布来逼近二项分布）：  
$\lambda$是一个大于零的常数，n是任意正整数，$\lambda =nP_n$,则对于任意固定的非负整数k，有：
$\lim\limits_{n \rightarrow +\infty} \frac{1}{n(n+1)}$
$$
\lim\limits_{n \rightarrow \infin} C_n^kp_n^k(1-p_n)^{n-k}=\frac{\lambda ^ke^{-\lambda}}{k!}
$$

## 2.3 随机变量的分布函数

### 定义
X是一个随机变量，x是任意实数，以下称为X的分布函数：
$$
F(x)=P(X\leq x),-\infin \leq x \leq +\infin
$$

$$
F(x)=\int_{-\infin}^x f(t)dt
$$

## 2.4 连续性随机变量

### 定义  
X为连续性随机变量，f(x)称为随机变量的概率密度。

### 性质  
1. $f(x)\geq 0$
2. $\int_{-\infin}^{+\infin}f(x)dx=1$
3. $P(x_1<X<x_2>)=F(x_2)-F(x_1)=\int_{x_1}^{x_2}f(x)dx$
4. 若f(x)在x处连续，则：
$F^\prime=F(x)$

### 均匀分布$X\sim U(a,b)$：  
$$
f(x)=
\begin{cases}
    \frac{1}{b-a} & a<x\leq b \\
    0 & else
\end{cases}
$$

### 指数分布  
$$
f(x)=
\begin{cases}
    \frac{1}{\theta}e^{-\frac{x}{\theta}}& x>0 \\
    0& else
\end{cases}
$$
指数分布具有无记忆性。

### 正太分布或高斯分布$X\sim N(\mu,\sigma^2)$:
$$
f(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{{x-\mu}^2}{2 \sigma^2}},-\infin < x < + \infin
$$
相关性质：
1. 关于$x=\mu$对称
2. $x=\mu$时取到最大值。$f(x)=\frac{1}{\sqrt{2\pi}}$
3. $Z=\frac{X-\mu}{\sigma}\sim N(0,1)$


# 3 多维随机变量

> 需要补充联合概率密度相关的内容，边缘概率密度

## 3.1 二维随机变量

### 二维随机变量定义  
随机实验$E$，样本空间$S=\{e\}$，$X=X(e),Y=Y(e)$是定义在$S$上的一个随机变量。由他们构成的向量$(X,Y)$称为二维随机变量

### 分布函数
设$(X,Y)$是二维随机变量，对于任意实数x，y，有
$$
F(x,y)=P((X\leq x)\cap(Y\leq y))\Leftrightarrow P(X\leq x,Y\leq y)
$$
称为二维随机变量(X,Y)的**分布函数**。或者随机变量X,Y的**联合分布函数**

### 分布函数的性质  
1. $F(x,y)$对于任意一个随机变量是一个不减函数。
2. $0\leq F(x,y) \leq 1$
3. $F(x,y)$关于x右连续，关于y右连续
4. $x_2 > x_1,y_2>y_1$
   $$
   F(x_2,y_2)-F(x_2,y_1)-F(x_1,y_2)+F(x_1,y_1)\geq 0
   $$

### 二维离散型随机变量联合分布律  
$$
P(X=x_i,Y=y_i)=p_{ij}
$$
称为二维离散随机变量(X,Y)的分布律，或者随机变量X，Y的联合分布律。

### 二维离散型随机变量(X,Y)的分布函数
$$
F(x,y)=\sum_{x_i\leq x}\sum_{y_i\leq y}p_{ij}
$$


### 二维连续型随机变量联合概率密度  
$$
f(x,y)
$$
称为二维连续型随机变量的概率密度或者随机变量X,Y的联合概率密度。

### 二维连续型随机变量(X,Y)的分布函数
$$
F(x,y)=\int_{-\infin}^y\int_{-\infin}^xf(u,v)dudv
$$

### 概率密度f(x,y)性质
1. $f(x,y)\geq 0$
2. $F(x,y)=\int_{-\infin}^{+\infin}\int_{-\infin}^{+\infin}f(u,v)dudv=1$
3. G是平面上的区域则：
$$
P((X,Y)\in G)=\iint_Gf(x,y)dxdy
$$
4. f(x,y)在点(x,y)处连续，
$$\frac{\partial^2 F(x,y)}{\partial x \partial y}=f(x,y)
$$

> n维随机变量的分布函数也具有以上性质。

## 3.2 边缘分布

### 边缘分布定义  
二维随机变量有各自的分布函数$F_x(x),Fy(y)$，称为二维随机变量的边缘分布。
$$
F_x(x)=P(X\leq x)=P(X\leq x,Y < \infin)=F(x,\infin)
$$

### 边缘分布律  
离散型随机变量(X,Y)的边缘分布律
$$
p_{i\cdot}=\sum_{j=1}^{\infin}p_{ij} \\
p_{\cdot j}=\sum_{i=1}^{\infin}p_{ij}
$$
连续型随机变量(X,Y)的边缘密度函数
$$
f_X(x)=\int_{-\infin}^{+\infin}f(x,y)dy \\
f_Y(y)=\int_{-\infin}^{+\infin}f(x,y)dx 
$$

## 3.3 条件分布

### 条件分布律定义  
二维随机变量(X,Y)，X在$Y_j$条件下的条件分布律为：
$$
P(X=x_i|Y=y_j)=\frac{p_{ij}}{p_{\cdot j}}
$$

### 条件概率密度定义
二维随机变量(X,Y)，X在Y=y条件下的条件概率密度：
$$
f_{X|Y}(x|y)=\frac{f(x,y)}{f_Y(y)}
$$


## 3.4 相互独立的随机变量

### 定义
$$
P(X\leq x,Y\leq y)=P(X\leq x)P(Y\leq y) \\
f(x,y)=f_X(x)f_Y(y)\\
F(x,y)=F_X(x)F_Y(y) \\
$$
满足上述条件的随机变量X与Y是相互独立的。

## 3.5 两个随机变量的函数的分布

### Z=X+Y的概率分布  
$$
f_{X+Y}(z)=\int_{-\infin}^{+\infin}f(z-y,y)dy \\
f_{X+Y}(z)=\int_{-\infin}^{+\infin}f(x,y-x)dx
$$
> 这个地方有点像二维积分通过关系式进行了简化（我可能又要重新复习高等数学的微积分知识了。

### 卷积公式  
如果X，Y两个随机变量相互独立，则能得到以下公式
$$
f_{X+Y}(z)=\int_{-\infin}^{+\infin}f_X(z-y)f_Y(y)dy \\
f_{X+Y}(z)=\int_{-\infin}^{+\infin}f_X(x)f_Y(z-x)dx
$$
这里的$f_X,f_Y$称为卷积公式。
> 很神奇，概率论矩阵啥的，最后还要用到基础的微积分数学工具。

### Z=Y/X与Z=XY的概率分布
$$
f_{X/Y}(z)=\int_{-\infin}^{+\infin}f(x,xz)dx \\
f_{XY}(z)=\int_{-\infin}^{+\infin}f(x,z/x)dx
$$
若果X，Y两个随机变量相互独立，则能得到以下公式
$$
f_{X/Y}(z)=\int_{-\infin}^{+\infin}f_X(x)f_Y(xz)dx \\
f_{XY}(z)=\int_{-\infin}^{+\infin}f_X(x)f_Y(z/x)dx
$$

### $M=max\{X,Y\},N=min\{X,Y\}$的概率分布
$$
P_{max}(z)=P({X\leq z},Y\leq z)\\
F_{max}(z)=F_X(z)F_Y(z) \\
F_{min}(z)=1-(1-F_X(z))(1-F_Y(z)) 
$$
> 可以将以上讨论扩展到n个随机变量

# 4. 随机变量的数字特征

> 这里并非统计量，而是估计量。即通过概率计算得到的总体的估计值，是数据特征。

## 4.1 数学期望或均值

> 主要包括数学期望的定义式，基本四则运算，与常见概率分布的数学期望的复杂运算。
### 定义  
离散型$E(X)=\sum_k^\infin x_kp_k$  
连续型$E(x)=\int_{-\infin}^{\infin}xf(x)dx$

### 常见数学期望
$$
X\sim \pi(\lambda);E(x)=\lambda \\
X\sim U(a,b);E(x)=\frac{a+b}{2}
$$


### 数学期望的性质
1. 常数期望不变：$E(C)=C$
2. 数称特性：$E(aX)=aE(X)$
3. 高维线性可加性XY不必独立：$E(X+Y)=E(X)+E(Y)$
4. 高维乘积X与Y相互独立：$E(XY)=E(X)E(Y)$


### 数学期望定理（运算公式）：
$$
Y=g(X),P(X=x_k)=p_k\\
E(Y)=E(g(X))=\sum_{k=1}^{\infin}g(x_k)p_k \\
E(Y)=E(g(x))=\int_{-\infin}^{\infin}g(x)f(x)dx
$$
利用定理可以直接计算变换后的函数密度。


## 4.2 方差

> 主要包括方差的定义式，基本四则运算，与常见概率分布的方差的复杂运算。
### 定义

定义式：$D(X)=Var(X)=E((X-E(X))^2)$  
离散型：$D(X)=\sum_1^\infin (x_k-E(X))^2p_k$  
连续型：$D(X)=\int_{-\infin}^{+\infin}(x-E(x))^2f(x)dx$  
简化式：$D(X)=E(X^2)-(E(X))^2$  

### 常见的方差  
$X\sim B(0,1),D(X)=p(1-p)$  
$X\sim N(\mu,\sigma^2),D(X)=\sigma^2$  
$X\sim \pi(\lambda)，D(X)=\lambda$    
$X\sim U(a,b),D(X)=\frac{(b-a)^2}{12}$

### 方差的性质
1. 常数不变性：C是常数，$D(C)=0$
2. 数乘特性：$D(CX)=C^2D(X)$
3. 高维独立可加性：若X，Y相互独立，则$D(X+Y)=D(X)+D(Y)$
4. $P(X=E(X))=1 \Leftrightarrow D(X)=0$

## 4.3 协方差与相关系数

> 主要包括协方差的定义式，基本四则运算。
### 定义
$$
Cov(X,Y)=E((X-E(X))(Y-E(Y))) \\
=E(XY)-E(X)E(Y)\\
样本=\sum(x_i-\overline{x})(y_i-\overline{y})\\
\rho_{XY}=\frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}
$$
X,Y 相互独立时，$Cov(X,Y)=0$

### 协方差含义
当求高数随机变量的方差时，如果随机变量不独立，会产生交叉项。高维乘积的方差，存在交叉项。
$$
D(X+Y)=E((X-E(X))^2)+E((Y-E(Y))^2)+2E((X-E(X))(Y-E(Y))) \\
D(X+Y)=D(X)+D(Y)+2Cov(X,Y) \\
$$
相关系数是协方差的标准化。用来表示X与Y的相关性。


### 协方差性质
1. 当X与Y独立时：$Cov(X,Y)=0$
2. C为常数:$Cov(X,C)=0$
3. 完全相关:$Cov(X,X)=D(X)$
4. 交换律:$Cov(X,Y)=Cov(Y,X)$
5. 线性可加性:$Cov(aX+c,bY+d)=abCov(X,Y)$
6. 分配率:$Cov(X_1+X_2,Y)=Cov(X_1,Y)+Cov(X_2,Y)$
7. 当X与Y不独立时：$D(X+Y)=D(X)+D(Y)+Cov(X,Y)$

### 相关系数性质
1. $|\rho_{XY}|\leq 1$
2. $|\rho_{XY}|=1 \Leftrightarrow P(Y=aX+b)=1$,即两者之间存在线性关系。
3. $\rho = 0$，XY两者不相关

## 4.4 矩、协方差矩阵

### 定义  
k阶原点矩：$E(X^k)$.  
k阶中心矩：$E((X-E(X))^k)$

### 切比雪夫不等式

随机变量X具有数学期望$E(X)=\mu,D(X)=\sigma^2$。对于任意正数$\epsilon$，不等式成立：
$$
P(|X-\mu|\geq\epsilon)\leq\frac{\sigma^2}{\epsilon^2} \\
或 P(|X-\mu|< \epsilon)\geq 1-\frac{\sigma^2}{\epsilon^2}
$$

> 相关性质以后再补充。


# 5. 大数定律和中心极限定理

## 5.1 大数定律

### 弱大数定理（辛钦大数定理） 
$X_1,X_2,\dotsm$独立同分布，$E(X_k)=\mu$，对于任意的$\epsilon \geq 0$，有：（可以证明）
$$
\lim\limits_{n\rightarrow 0}P(|\frac{1}{n}\sum_{k=1}^nx_k-\mu|<\epsilon)=1
$$
$\overline{X}=\frac{1}{n} \sum_{k=1}^nx_k$算术平拘束依概率收敛于$\mu$,即$\overline{X}\xrightarrow{P}\mu$

### 伯努利大数定理
设$f_A$是n次实验中事件A发生的次数，P是每次实验中A发生的概率。则有(可以理解)
$$
\lim\limits_{n\rightarrow\infin}P(|\frac{f_A}{n}-p|<\epsilon)=1 \\
\lim\limits_{n\rightarrow\infin}P(|\frac{f_A}{n}-p|\geq\epsilon)=0
$$


## 5.2 中心极限定理

### 定理一（独立同分布的中心极限定理）
$X_1,X_2,\dotsm$独立同分布，$E(X_k)=\mu,D(X_k)=\sigma^2$,则随机化变量之和的标准化变量为：
$$
Y_n=\frac{\sum_{k=1}^nX_k-n\mu}{\sqrt{n}\sigma}
$$
它的概率分布为：
$$
\lim\limits_{n\rightarrow\infin}F_n(x)=\int_{-\infin}^x\frac{1}{\sqrt{2\pi}}e^{\frac{-t^2}{2}}dt
$$
含义说明：$E(X_k)=\mu,D(X_k)=\sigma^2$的独立同分布的随机变量的和的标准化变量$Y_n$，当n足够大时，近似服从标准化正太分布。

### 定理二（李雅普诺夫定理）
$X_1,X_2,\dotsm$相互独立，但并不是同分布。
$E(X_k)=\mu_k,D(X_k)=\sigma_k^2$,则随机化变量之和的标准化变量为：
$$
Z_n=\frac{\sum_{k=1}^nX_k-\sum_{k=1}^n\mu_k}{\sum_{k=1}^n\sigma_k^2}
$$
它的概率分布为：
$$
\lim\limits_{n\rightarrow\infin}F_n(x)=\int_{-\infin}^x\frac{1}{\sqrt{2\pi}}e^{\frac{-t^2}{2}}dt
$$
含义说明，无论各个随机变量服从什么样的分布，当n足够大时，他们和的标准化变量$Z_n$都服从正太分布。

### 定理三（迪莫夫拉普拉斯定理） 
设随机变量$\eta_n$服从(n,p)二项分布。对于任意的x有：

$$
\lim\limits_{n\rightarrow\infin}P(\frac{\eta_n-np}{\sqrt{np(1-p)}}\leq x)=\int_{-\infin}^x\frac{1}{\sqrt{2\pi}}e^{\frac{-t^2}{2}}dt
$$
含义说明：正态分布是二项分布的极限分布。


> 总结说明
> 1. 首先给出了**随机事件**、**事件概率**等定义，说明了**事件之间的运算**：交事件和事件。
> 2. 用**随机变量**对应随机事件，给出了随机变量的定义，说明了离散型随机变量的**分布律**与连续性随机变量的**概率密度**。并说明了**随机变量之间的运算**与分布律之间的关系。
> 3. 多个随机变量构成了**样本**，然后指出了样本的概率统计。随机变量的**统计量**是对随机变量的一种描述。所有的统计量都是随机变量的函数。能够进行**统计量之间的运算**
